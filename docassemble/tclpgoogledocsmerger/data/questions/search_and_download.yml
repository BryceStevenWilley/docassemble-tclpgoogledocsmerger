---
imports:
  - mammoth
  - base64
---
features:
  css: bootstrap-multiselect.min.css
  javascript: bootstrap-multiselect.min.js
  # https://davidstutz.github.io/bootstrap-multiselect/#getting-started
---
metadata:
  title: TCLP Search and Download
  short title: Search
---
modules:
  - .drive_connection
  - .data
---
code: |
  selectable_column_info = [
    ('GIC Industry', 'GIC Industry', 'https://en.wikipedia.org/wiki/Global_Industry_Classification_Standard', False),
    #('GIC Industry Group', 'GIC Industry Group', 'https://en.wikipedia.org/wiki/Global_Industry_Classification_Standard', False),
    #('COP26 Net Zero Chapter', 'COP26 Net Zero Chapter', '', False),
    ('Practice Area', 'Practice Area', '', False),
  ]
  combined_field = [
    ('F - Corp Gov', 'Corporate governance', '', True),
    ('F - Contract Emissions', 'Contract emissions', '', True),
    ('F - Organisation emissions', 'Organisation emissions', '', True),
    ('F - Reporting & Disclosures', 'Reporting & Disclosures', '', True),
    ('F - Corporate Mechanisms', 'Corporate Mechanisms', '', True),
    ('F - Incentives, Enforcement, Disputes', 'Incentives, Enforcement, Disputes', '', True),
    ('F - Other environmental function', 'Other environmental func.', '', True),
    ('F - Pre-contract', 'Pre-contract', '', True),
    ('F - Just Transition', 'Just Transition', '', True),
    ('F - Resilience & Adaptation', 'Resillence & Adaptation', '', True),
    ('F - Biodiversity', 'Biodiversity', '', True),
  ]
  selectable_columns = [a for a, _, _, _ in selectable_column_info] + [a for a, _, _, _ in combined_field]
  all_fields = selectable_columns # + ['top_level_' + a for a, _, _, top_level in selectable_column_info if top_level]
---
objects: 
  - filled_template: DADict
  - multi_index: MultiSelectIndex.using(import_path=static_file.path(), cols_with_indices=selectable_columns)
---
objects:
  - static_file: DAStaticFile.using(filename='data/sources/Grid_view.csv')
---
id: Main order block
mandatory: True
code: |
  snapshot_interview_state
  accept_gdpr_notice
  reconsider('snapshot_interview_state')
  prep_documents
  the_download_task
  review_before_download
  if the_download_task.ready() and the_assembly_task.ready():
    reached_download_screen = True
    reconsider('snapshot_interview_state')
    download_filled
  else:
    waiting_screen
---
code: |
  selectable_fields = []
  all_types = {}
  selected_type = {}
  for col, label, help_link, is_top_level in selectable_column_info:
    all_types[col] = multi_index.get_values(col)
    #if is_top_level:
    #  top_level_var = "top_level_" + col
    #  selectable_fields.append(
    #          {'label': 'any ' + label, 'field': f'selected_type["{top_level_var}"]',
    #           'datatype': 'yesno', 'required': False})
    selectable_fields.append(
          {'label': label, 'field': f'selected_type["{col}"]', 'datatype': 'ourmultiselect', 
           'required': False, 'code_options': f'all_types["{col}"]'})
    #if is_top_level:
    #  selectable_fields[-1]['show if'] = f'selected_type["{top_level_var}"]'
    if help_link:
      selectable_fields[-1]['help'] = f'[More info here]({help_link})'

  single_selectable_type = []
  all_combined_types = []
  for col, label, help_link, is_top_level in combined_field:
    all_combined_types.extend(multi_index.get_values(col))
  
  selectable_fields.append(
        {'label': 'Functions', 'field': f'single_selectable_type', 
         'datatype': 'multiselect',
         'required': False, 'code': 'all_combined_types' })
---
code: |
  # Take the interesting fields and make them 2 dimensional so easier to view in XLSX
  stuff_to_snapshot = {
     'start_time': str(start_time().format('yyyy-MM-dd')),
     }    
  # Get location
  try:
    import requests
    resp = requests.get(f"https://geolocation-db.com/json/{device(ip=True)}&position=true").json()
    stuff_to_snapshot['country'] = resp.get('country_code')
    stuff_to_snapshot['state'] = resp.get('state')
    stuff_to_snapshot['city'] = resp.get('city')
    stuff_to_snapshot['latitude'] = round(resp['latitude'] * 100) / 100 if 'latitude' in resp else None
    stuff_to_snapshot['longitude'] = round(resp['longitude'] * 100) / 100 if 'longitude' in resp else None
  except:
    stuff_to_snapshot['country'] = 'UNKNOWN'
  # Don't let DA parse nameerrors so that all data is recorded in one block,
  # regardless of how far in interview someone got
  try:
    stuff_to_snapshot['all_clauses'] = comma_list(all_clauses)
    stuff_to_snapshot['all_clauses_full_names'] = comma_list(f'"{clause.full_name}"' for clause in all_clause_objects)
    stuff_to_snapshot['selected_rows'] = comma_list([row[1]["Child's name"] for row in selected_rows.iterrows()])
    if defined('selected_type'):
      for column in selected_type:
        if selected_type[column].any_true():
          stuff_to_snapshot[f"column_{column}"] = comma_list(selected_type[column].true_values())
  except:
    pass
    
  stuff_to_snapshot['reached_download_screen'] = defined('reached_download_screen')
  store_variables_snapshot(
      data=stuff_to_snapshot, persistent=True
     )
  snapshot_interview_state = True
---
code: |
  full_clauses_folder_id =  "1YDT_u4AJMzwJKNcAH2naYHhycNd-iHvt"
  all_files = get_files_in_folder(folder_id=full_clauses_folder_id)
---
id: search variables
question: |
  Build a custom climate clause document
subquestion: |
  Use the search options to create your own custom document with climate-friendly terms you 
  can use in your contracts.
fields:
  - code: selectable_fields
  - no label: accept_gdpr_notice
    datatype: checkboxes
    choices:
      - I have read and understand the [data privacy policy](https://www.example.com)
    minlength: 1
    none of the above: False
    validation messages:
      minlength: |
        You need to accept the data privacy policy to continue.
validation code: |
   indiv_any_trues = [bool(a_type) and (not isinstance(a_type, list) or a_type.any_true()) for a_type in selected_type.values()]
   if not any(indiv_any_trues):
    validation_error("You need to search for at least one thing")
  # TODO: do we really want to require a search term, or should no limits return
  # everything? currently getting a StopIteration error without this code though
#script: |
#  <script type="text/javascript">
#      $(document).ready(function() {
#          % for col_name in selectable_columns:
#          $("#${ base64.b64encode(str('selected_type["' + col_name + #'"]').encode()).decode().replace('=', '') } ").multiselect({enableCaseInsensitiveFiltering: #true, inheritClass: true});
#          % endfor
#      });
#  </script>      
---
comment: |
  - Corporate Governance: use_coporate_governance
    datatype: yesnowide
  - Contract emissions: use_contract_emissions
    datatype: yesnowide
  - Organization emissions: use_organization_emissions
    datatype: yesnowide
  - Reporting & Disclosures: use_reporting_and_disclosures
    datatype: yesnowide
  - Corporate Mechanisms: use_roporate_mechanisms
    datatype: yesnowide
  - Incentives, Enforcement, Disputes: use_incentives
    datatype: yesnowide
  - Other environmental function: use_other_environmental_function
    datatype: yesnowide
  - Pre-contract: use_pre_contract
    datatype: yesnowide
  - Just Transition: use_just_transition
    datatype: yesnowide
  - Resillience & Adaptiation: use_resillience
    datatype: yesnowide
  - Biodiversity: use_biodiversity
    datatype: yesnowide
---
id: select rows
code: |
  query_list = []
  for col_name in all_fields:
    col_vals = selected_type.get(col_name)
    if isinstance(col_vals, DADict):
      if col_vals.any_true():
        query_list.append([col_name, col_vals.true_values()])
    elif isinstance(col_vals, bool):
      query_list.append([col_name])
    elif col_vals != "":
      query_list.append((col_name, [col_vals]))
  row_ids = multi_index.query(query_list)
  #del query_list
---
id: prep documents
code: |
  url_base_str = 'https://chancerylaneproject.org/climate-clauses/{}'
  all_clause_ids = []
  all_clauses = []
  all_clause_objects = []
  selected_rows = multi_index.get_full_rows(row_ids) 
  for row in selected_rows.iterrows():
    these_ids = []
    g_files = get_files_for_clause(all_files, row[1]["Child's name"])
    if g_files:
      all_clauses.append(row[1]["Child's name"])
    for g_file in g_files:
      modified_time = g_file.get('modifiedTime')
      if 'id' in g_file:
        these_ids.append(g_file.get('id'))
        all_clause_ids.append(g_file.get('id'))
    if g_files:
      full_name = row[1]['Full name']
      url = url_base_str.format(row[1]['Full name'].lower().replace(' ', '-'))
      all_clause_objects.append(DAObject(
        name=row[1]["Child's name"],
        full_name=full_name,
        modified_time=modified_time,
        url=url,
        docx_link=f'[{full_name}]({url})',
        file_ids=these_ids
      ))
  # all_clause_docs2 = download_drive_files_docx(all_clause_ids, 'doc_')
  prep_documents = True
---
code: |
  the_download_task = background_action('download_task', all_clauses=all_clause_objects)
---
code: |
  the_assembly_task = background_action('assemble_task', all_clauses=all_clause_objects)
---
event: download_task
code: |
  all_clauses = action_argument('all_clauses')
  for obj in all_clauses:
    obj.files = download_drive_files_docx(obj.file_ids, 'doc_')
  filled_template['final']
  background_response_action('download_resp', new_clauses=all_clauses)
---
event: download_resp
code: |
  all_clause_objects = action_argument('new_clauses')
  background_response()
---
event: assemble_task
code: |
  all_clause_objects = action_argument('all_clauses')
  filled_template['final']
  background_response_action('assemble_resp', the_doc=filled_template['final'])
---
event: assemble_resp
code: |
  the_doc = action_argument('the_doc')
  background_response()
---
id: Review before downloading
question: |
  % if all_clauses:
  Review your clauses
  % else:
  No matching clauses found.
  % endif
subquestion: |
  % if all_clauses:

  Here is more about the individual clauses that we found.
  
  % for obj in all_clause_objects:
  * [${ obj.name }: ${ obj.full_name }](${obj.url})
      * Last modified at ${ format_datetime(obj.modified_time) }
  % endfor

  % else:
  
  We couldn't find anything that matched all of the attributes that you searched for. Try reducing the number of attributes.
  
  % endif
continue button field: review_before_download
---
event: waiting_screen
id: waiting screen
question: |
  We're assembling your documents now
subquestion: |
  Hang tight, we'll refresh this page when your document is ready.
reload: True
---
id: download filled
event: download_filled
question: |
  % if all_clauses:
  Download Your Completed Document
  % else:
  No matching clauses found.
  % endif
comment: |
  Download the [combined document with all of the found clauses](${ the_doc.url_for() }).
subquestion: |
  % if all_clauses:
  
  [:file-download: Download](${the_doc.url_for(attachment=True)})

  Here is more about the individual clauses that we found.
  
  % for obj in all_clause_objects:
  * [${ obj.name }: ${ obj.full_name }](${obj.url})
      * Last modified at ${ format_datetime(obj.modified_time) }
  % endfor

  % else:
  
  We couldn't find anything that matched all of the attributes that you searched for. Try reducing the number of attributes.
  
  % endif
---
attachment:
  variable name: filled_template[i]
  name: Requested Clauses
  filename: requested_clauses
  skip undefined: True
  docx template file: ClausesTemplate.docx
  update references: True
